{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.models import Sequential, load_model, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, Input, MaxPooling2D, concatenate, AveragePooling1D, Reshape, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy, Reduction\n",
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras.activations import softmax\n",
    "from tensorflow import roll, norm, add\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow.keras.applications as A\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import fnmatch\n",
    "import cv2\n",
    "import json\n",
    "\n",
    "import include.supervisely_parser as svp\n",
    "import include.grid_parser as gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_path = './annotation_v0.1/'\n",
    "image_path = './data/Mikrowunderland_1k/'\n",
    "x_values = 240\n",
    "y_values = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "debug = []\n",
    "segmented_debug = []\n",
    "data = []\n",
    "\n",
    "def preprocess(img):\n",
    "    height, _, _ = img.shape\n",
    "    img = img[int(height/2):,:,:]\n",
    "    return img\n",
    "def debug_image_from_grid(grid):\n",
    "    img = np.zeros((y_values, x_values, 3))\n",
    "    for lane in range(len(grid)):\n",
    "        lane_c = grid[lane]\n",
    "        for y in range(len(lane_c)):\n",
    "            non_zero = np.nonzero(lane_c[y])\n",
    "            for x in non_zero:\n",
    "                img[y, x,lane] = 1.0\n",
    "    return img\n",
    "\n",
    "file_list = os.listdir(annotation_path)\n",
    "pattern = '*.json'\n",
    "for filename in file_list:\n",
    "    if fnmatch.fnmatch(filename, pattern):\n",
    "        ann_data_path = os.path.join(annotation_path, filename)\n",
    "        image_name = os.path.splitext(filename)[0]\n",
    "        image_data_path = os.path.join(image_path, image_name)\n",
    "        \n",
    "        # extract lanes from ann data\n",
    "        lanes = svp.getPoints(ann_data_path)\n",
    "        if len(lanes.keys()) > 0:\n",
    "            # only if this image has annotation data\n",
    "            img = cv2.imread(image_data_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            blank = np.zeros(img.shape)\n",
    "            segmented = svp.drawLanes(blank, lanes)\n",
    "            # preprocess both images\n",
    "            segmented = preprocess(segmented)\n",
    "            \n",
    "            grid = gp.segmented_image_into_grid_space(segmented, grid_size=(y_values, x_values), window_size_x=10)\n",
    "\n",
    "            img = preprocess(img)\n",
    "            img = cv2.resize(img, (434, 150))\n",
    "\n",
    "            images.append(img)\n",
    "            debug.append(debug_image_from_grid(grid))\n",
    "            data.append(grid)\n",
    "            segmented_debug.append(segmented)\n",
    "\n",
    "\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 10\n",
    "f, axs = plt.subplots(c, 3, figsize=(20,c*3))\n",
    "i = 0\n",
    "print(data[i].shape)\n",
    "for y in range(c):\n",
    "    axs[y,0].imshow(images[i])\n",
    "    axs[y,1].imshow(debug[i])\n",
    "    axs[y,2].imshow(segmented_debug[i])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 275\n",
      "Validation data: 69\n"
     ]
    }
   ],
   "source": [
    "img_train, img_valid, data_train, data_valid = train_test_split(images, data, test_size=0.2)\n",
    "print(\"Training data: %d\\nValidation data: %d\" % (len(img_train), len(img_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOSS FUNCTIONS\n",
    "number_lanes = 3\n",
    "num_rows = y_values\n",
    "num_classes = x_values\n",
    "\n",
    "def loss_cls(y_true, y_pred):\n",
    "    y_true = K.cast(y_true, 'float32')\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    \n",
    "    true_shaped = K.reshape(y_true, shape=(-1,number_lanes,num_rows, num_classes))\n",
    "    pred_shaped = K.reshape(y_pred, shape=(-1,number_lanes,num_rows, num_classes))\n",
    "    bce = CategoricalCrossentropy(reduction=Reduction.SUM, )\n",
    "    bce_val = bce(true_shaped, pred_shaped)\n",
    "    \n",
    "    return bce_val\n",
    "\n",
    "def loss_sim(y_true, y_pred):\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "\n",
    "    pred_shaped = K.reshape(y_pred, shape=(-1,number_lanes,num_rows, num_classes))\n",
    "    pred_shaped_plus1 = roll(pred_shaped, shift=-1, axis=2)\n",
    "    \n",
    "    subtracted = pred_shaped - pred_shaped_plus1\n",
    "    removed_last_row = Lambda(lambda x: x[:, :, :num_rows-1, :])(subtracted)\n",
    "    \n",
    "    l1_norm = norm(removed_last_row, ord=1, axis=-1, keepdims=False)\n",
    "    lane_sum = K.sum(l1_norm, axis=2)\n",
    "    return K.sum(lane_sum)\n",
    "\n",
    "def loss_total(y_true, y_pred):\n",
    "    cls_ = loss_cls(y_true, y_pred)\n",
    "    sim_ = loss_sim(y_true, y_pred)\n",
    "    return add(cls_,sim_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_cls_model(total_dim, name):\n",
    "    base_model = A.ResNet50V2(include_top=False, weights=\"imagenet\", input_shape=(180,340,3)) \n",
    "    \n",
    "    pool = Conv2D(8, (1, 1))(base_model.output)\n",
    "    \n",
    "    flatten = Flatten()(pool)\n",
    "    \n",
    "    cls_group = Dense(256, activation=\"relu\")(flatten)\n",
    "    cls_group = Dropout(0.4)(cls_group)\n",
    "    cls_group = Dense(total_dim)(cls_group)\n",
    "    \n",
    "    output = Reshape((number_lanes,num_rows, num_classes))(cls_group)\n",
    "    output = Activation('softmax')(output)\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=output, name=name)\n",
    "    optimizer = Adam(lr=4e-4) # lr is learning rate\n",
    "    model.compile(loss=loss_total, optimizer=optimizer) # mean squared error because it is a regression problem\n",
    "    plot_model(model, to_file='%s.png' % (name))\n",
    "    return model\n",
    "def pretrained_model():\n",
    "    return load_model('ld_sim_base.h5', custom_objects={'loss_total': loss_total})\n",
    "    #return load_model('ld_sim_base.h5', custom_objects={'loss_total': loss_total})\n",
    "    \n",
    "model = res_cls_model(np.prod((number_lanes,num_rows, num_classes)), 'AUTOSYS_LANEDETECTION_CLS')\n",
    "#model = res_cls_model()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparamter\n",
    "my_batch_size = 8\n",
    "my_epochs = 20\n",
    "# checkpoint\n",
    "filepath=\"weights-improvement-{epoch:02d}-{val_loss:.2f}.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "history = model.fit(img_train, data_train,\n",
    "                   batch_size=my_batch_size,\n",
    "                   epochs=my_epochs,\n",
    "                   verbose=1,\n",
    "                   validation_data=(img_valid, data_valid),\n",
    "                   callbacks=callbacks_list)\n",
    "\n",
    "model.save('ld_autosys.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_ml",
   "language": "python",
   "name": "env_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}