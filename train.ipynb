{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install segmentation-models albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.models import Sequential, load_model, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, Input, MaxPooling2D, concatenate, AveragePooling1D, Reshape, Activation, add, Conv2DTranspose, BatchNormalization, UpSampling2D, SeparableConv2D\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy, Reduction, BinaryCrossentropy\n",
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras.activations import softmax\n",
    "from tensorflow import roll, norm, add\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow.keras.applications as A\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import fnmatch\n",
    "import cv2\n",
    "import json\n",
    "\n",
    "import include.supervisely_parser as svp\n",
    "import include.grid_parser as gp\n",
    "\n",
    "import segmentation_models as sm # for simple segmentation architecture\n",
    "import albumentations as Alb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_path = './annotation_v0.2/'\n",
    "image_path = './data/Mikrowunderland_1k/'\n",
    "model_path = './model/ld_autosys.h5'\n",
    "number_classes = 5 # outer_l, outer_t, outer_r, middle_curb\n",
    "x_values = 192\n",
    "y_values = 48\n",
    "\n",
    "input_width = 434\n",
    "input_height = 150\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(img):\n",
    "    height, _, _ = img.shape\n",
    "    img = img[int(height/2):,:,:]\n",
    "    return img\n",
    "def preprocess_gray(img):\n",
    "    height, _ = img.shape\n",
    "    img = img[int(height/2):,:]\n",
    "    return img\n",
    "transform = Alb.Compose([\n",
    "    Alb.ShiftScaleRotate(p=1.0),\n",
    "    Alb.RandomContrast(),\n",
    "    Alb.RandomBrightness()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "segmented_debug = []\n",
    "data = []\n",
    "\n",
    "file_list = os.listdir(annotation_path)\n",
    "pattern = '*.json'\n",
    "for filename in file_list:\n",
    "    if fnmatch.fnmatch(filename, pattern):\n",
    "        ann_data_path = os.path.join(annotation_path, filename)\n",
    "        image_name = os.path.splitext(filename)[0]\n",
    "        image_data_path = os.path.join(image_path, image_name)\n",
    "        \n",
    "        # extract lanes from ann data\n",
    "        lanes = svp.getPoints(ann_data_path)\n",
    "        if len(lanes.keys()) > 0:\n",
    "            # only if this image has annotation data\n",
    "            img = cv2.imread(image_data_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            segmented_data = svp.drawLanes((img.shape[0], img.shape[1]), lanes)\n",
    "            segmented_debug_image = svp.drawDebugImage(np.zeros(img.shape), lanes)\n",
    "            merged = cv2.merge([cv2.resize(preprocess_gray(segmented), (x_values, y_values)) for segmented in segmented_data])\n",
    "            #grid = gp.segmented_image_into_grid_space(merged, grid_size=(y_values, x_values), window_size_x=2)\n",
    "            #grid = np.reshape(grid, (-1, y_values, x_values, number_classes))\n",
    "            preprocessed_image = img\n",
    "            img = preprocess(img)\n",
    "            img = cv2.resize(img, (input_width, input_height))\n",
    "            segmented_debug_image = preprocess(segmented_debug_image)\n",
    "            images.append(img)\n",
    "            data.append(merged)\n",
    "            segmented_debug.append(segmented_debug_image)\n",
    "\n",
    "\n",
    "            # augment this dataset\n",
    "            transformed = transform(image=preprocessed_image, masks=segmented_data)\n",
    "            new_image = transformed['image']\n",
    "            new_image = preprocess(new_image)\n",
    "            new_image = cv2.resize(new_image, (input_width, input_height))\n",
    "            images.append(cv2.resize(new_image, (input_width, input_height)))\n",
    "            new_masks = np.array(transformed['masks'])\n",
    "            new_masks = cv2.merge([cv2.resize(preprocess_gray(mask), (x_values, y_values)) for mask in new_masks])\n",
    "            #new_masks = cv2.merge([mask for mask in segmented_data])\n",
    "            data.append(new_masks)\n",
    "            segmented_debug.append(segmented_debug_image)\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 10\n",
    "f, axs = plt.subplots(c, 7, figsize=(50,c*3))\n",
    "i = 0\n",
    "print(len(images))\n",
    "for y in range(c):\n",
    "    axs[y,0].imshow(images[i])\n",
    "    axs[y,1].imshow(segmented_debug[i])\n",
    "    axs[y,2].imshow(data[i][:,:,0], cmap='plasma')\n",
    "    axs[y,3].imshow(data[i][:,:,1], cmap='plasma')\n",
    "    axs[y,4].imshow(data[i][:,:,2], cmap='plasma')\n",
    "    axs[y,5].imshow(data[i][:,:,3], cmap='plasma')\n",
    "    axs[y,6].imshow(data[i][:,:,4], cmap='plasma')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.array(images)\n",
    "data = np.array(data)\n",
    "\n",
    "img_train, img_valid, data_train, data_valid = train_test_split(images, data, test_size=0.2)\n",
    "print(\"Training data: %d %d\\nValidation data: %d %d\" % (len(img_train), len(data_train), len(img_valid), len(data_valid)))\n",
    "print(img_train.shape)\n",
    "print(data_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run only if segmentation models will be used\n",
    "BACKBONE = 'inceptionv3'\n",
    "K.set_image_data_format('channels_last')\n",
    "preprocess_input = sm.get_preprocessing(BACKBONE)\n",
    "\n",
    "img_train = preprocess_input(img_train)\n",
    "img_valid = preprocess_input(img_valid)\n",
    "\n",
    "print(img_train.shape)\n",
    "print(data_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_custom(name):\n",
    "   # base_model = A.ResNet50V2(include_top=False, weights=\"imagenet\", input_shape=(input_height,input_width,3)) \n",
    "    base_model = A.InceptionV3(include_top=False, weights=\"imagenet\", input_shape=(input_height,input_width,3)) \n",
    "    #base_model = A.VGG16(include_top=False, weights=\"imagenet\", input_shape=(input_height,input_width,3))\n",
    "    pool = Conv2D(512, (1, 1))(base_model.output)\n",
    "    x = Conv2DTranspose(256, 3, strides=(2,2), padding='same')(pool)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    for filters in [128, 64, 32]:\n",
    "        x = Conv2DTranspose(filters, 3, strides=(2,2), padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Dropout(0.4)(x)\n",
    "    output = Conv2D(number_classes, 1)(x)\n",
    "    output = Activation('softmax')(output)\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=output, name=name)\n",
    "    optimizer = Adam(lr=1e-4) # lr is learning rate\n",
    "    loss = sm.losses.CategoricalCELoss() + sm.losses.DiceLoss()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=[sm.metrics.iou_score]) # mean squared error because it is a regression problem\n",
    "    #plot_model(model, to_file='%s.png' % (name))\n",
    "    return model\n",
    "\n",
    "\n",
    "def custom_unet():\n",
    "    inputs = Input(shape=(input_height,input_width,3))\n",
    "    ### [First half of the network: downsampling inputs] ###\n",
    "    # Entry block\n",
    "    x = Conv2D(32, 3, strides=2, padding=\"same\")(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    previous_block_activation = x  # Set aside residual\n",
    "    # Blocks 1, 2, 3 are identical apart from the feature depth.\n",
    "    for filters in [64, 128, 256]:\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "        x = MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = Conv2D(filters, 1, strides=2, padding=\"same\")(\n",
    "            previous_block_activation\n",
    "        )\n",
    "        x = tf.keras.layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    ### [Second half of the network: upsampling inputs] ###\n",
    "\n",
    "    for filters in [256, 128, 64, 32]:\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "        x = UpSampling2D(2)(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = UpSampling2D(2)(previous_block_activation)\n",
    "        residual = Conv2D(filters, 1, padding=\"same\")(residual)\n",
    "        x = tf.keras.layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    # Add a per-pixel classification layer\n",
    "    outputs = Conv2D(number_classes, 3, activation=\"softmax\", padding=\"same\")(x)\n",
    "    # Define the model\n",
    "    model = Model(inputs, outputs)\n",
    "    loss = sm.losses.CategoricalCELoss()\n",
    "    loss = sm.losses.DiceLoss()\n",
    "    model.compile(optimizer=\"rmsprop\", loss=loss, metrics=[sm.metrics.iou_score])\n",
    "    return model\n",
    "def segmentation_model():\n",
    "    model = sm.Unet(BACKBONE, encoder_weights='imagenet', classes=number_classes, activation='softmax')\n",
    "    optimizer = Adam(lr=4e-4) # lr is learning rate\n",
    "    loss = sm.losses.DiceLoss()\n",
    "    loss = sm.losses.CategoricalCELoss()\n",
    "    model.compile(optimizer = optimizer, loss=loss, metrics=[sm.metrics.iou_score])\n",
    "    return model\n",
    "    \n",
    "model = test_custom('AUTOSYS_LANEDETECTION_CLS')\n",
    "#model = custom_unet()\n",
    "#model = segmentation_model()\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparamter\n",
    "my_batch_size = 8\n",
    "my_epochs = 60\n",
    "# checkpoint\n",
    "filepath=\"weights-improvement-{epoch:02d}-{val_loss:.2f}.h5\"\n",
    "#checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "#callbacks_list = [checkpoint]\n",
    "\n",
    "history = model.fit(img_train, data_train,\n",
    "                   batch_size=my_batch_size,\n",
    "                   epochs=my_epochs,\n",
    "                   verbose=1,\n",
    "                   validation_data=(img_valid, data_valid))#,\n",
    "                   #callbacks=callbacks_list)\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation iou_score values\n",
    "plt.figure(figsize=(30, 5))\n",
    "plt.subplot(121)\n",
    "plt.plot(history.history['iou_score'])\n",
    "plt.plot(history.history['val_iou_score'])\n",
    "plt.title('Model iou_score')\n",
    "plt.ylabel('iou_score')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.subplot(122)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.savefig('inceptionv3_60epoch_4conv2d.png')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model only if not trained in this session\\\n",
    "model = load_model('./model/ld_autosys2.h5', custom_objects={'loss_total':loss_total})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load some test images\n",
    "file_list = os.listdir(annotation_path)\n",
    "pattern = '*.json'\n",
    "cnt = 15\n",
    "test_imgs = []\n",
    "\n",
    "for filename in file_list:\n",
    "    if fnmatch.fnmatch(filename, pattern):\n",
    "        ann_data_path = os.path.join(annotation_path, filename)\n",
    "        image_name = os.path.splitext(filename)[0]\n",
    "        image_data_path = os.path.join(image_path, image_name)\n",
    "        # extract lanes from ann data\n",
    "        lanes = svp.getPoints(ann_data_path)\n",
    "        # only images without annotation\n",
    "        if len(lanes.keys()) == 0:\n",
    "            img = cv2.imread(image_data_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = preprocess(img)\n",
    "            img = cv2.resize(img, (input_width, input_height))\n",
    "\n",
    "            test_imgs.append(img)\n",
    "            cnt -= 1\n",
    "            if cnt == 0:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(np.array(test_imgs))\n",
    "\n",
    "thres_value = 0.3\n",
    "\n",
    "def postprocess_channel(img):\n",
    "    #img = cv2.medianBlur(img, 3)\n",
    "    _, img = cv2.threshold(img,thres_value,1.0,cv2.THRESH_BINARY)\n",
    "    return img\n",
    "\n",
    "f, axs = plt.subplots(len(predictions), 6, figsize=(50,len(predictions)*3))\n",
    "for i, prediciton in enumerate(predictions):\n",
    "    #test_img = cv2.resize(test_imgs[i], (x_values, y_values))\n",
    "    test_img = test_img/255\n",
    "    test_img = test_img.astype(np.float32)\n",
    "    predicted_lanes = np.sum([postprocess_channel(prediciton[:,:,i]) for i in range(4)], axis=0)\n",
    "    predicted_lanes = cv2.merge([np.zeros_like(predicted_lanes), np.zeros_like(predicted_lanes), predicted_lanes])\n",
    "    predicted_lanes = cv2.resize(predicted_lanes, (test_img.shape[1], test_img.shape[0]))\n",
    "    overlay_image = cv2.addWeighted(test_img, 0.5, predicted_lanes, 0.5, 0)\n",
    "    axs[i,0].imshow(overlay_image)\n",
    "    #axs[i,0].imshow(test_imgs[i])\n",
    "    axs[i,1].imshow(postprocess_channel(prediciton[:,:,0]), cmap='plasma')\n",
    "    axs[i,2].imshow(postprocess_channel(prediciton[:,:,1]), cmap='plasma')\n",
    "    axs[i,3].imshow(postprocess_channel(prediciton[:,:,2]), cmap='plasma')\n",
    "    axs[i,4].imshow(postprocess_channel(prediciton[:,:,3]), cmap='plasma')\n",
    "    axs[i,5].imshow(postprocess_channel(prediciton[:,:,4]), cmap='plasma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}