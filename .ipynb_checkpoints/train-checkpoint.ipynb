{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install segmentation-models albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# include include folder\n",
    "import sys\n",
    "sys.path.append(\"./miniaturautonomie_lanedetection/include/\")\n",
    "sys.path.append(\"./include/\")\n",
    "\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import fnmatch\n",
    "import random\n",
    "import cv2\n",
    "import json\n",
    "\n",
    "import supervisely_parser as svp\n",
    "import grid_parser as gp\n",
    "import render\n",
    "from DataGenerator import DataGenerator\n",
    "\n",
    "import albumentations as Alb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_path = './annotation_v3.0/'\n",
    "image_path = './data/'\n",
    "packages = ['knuff_main1', 'knuff_main2', 'knuff_main3', 'knuff_hill', 'uni', 'highway', 'knuff_main5', 'knuff_main6']\n",
    "\n",
    "model_path = './model/ld_autosys.h5'\n",
    "\n",
    "input_img_size = (480, 640)\n",
    "\n",
    "number_classes = 7 # outer, middle_curb, guide_lane, solid_lane, hold_line, zebra, background\n",
    "output_width = 640 \n",
    "output_height = 224 \n",
    "input_width = 640 \n",
    "input_height = 224\n",
    "\n",
    "val_size = 0.2 # percentage\n",
    "augmentation = False\n",
    "\n",
    "batch_size = 16\n",
    "epochs = 5\n",
    "\n",
    "transform = Alb.Compose([\n",
    "    Alb.ShiftScaleRotate(p=0.2),\n",
    "    Alb.RandomContrast(p=0.4),\n",
    "    Alb.RandomBrightness(limit=[-0.4,0.2], p=0.4)\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'batch_size': batch_size,\n",
    "    'input_img_size': input_img_size,\n",
    "    'target_img_size': (output_height, output_width),\n",
    "    'shuffle': True,\n",
    "    'n_channels': number_classes,\n",
    "    'transform': transform,\n",
    "    'augmentation': augmentation\n",
    "}\n",
    "\n",
    "#################################################################\n",
    "# run only if to rerender all masks or new packages are added\n",
    "#render.render_packages(packages, annotation_path, input_img_size)\n",
    "#################################################################\n",
    "\n",
    "# generate absolute list of all img and masks paths\n",
    "image_paths = []\n",
    "mask_paths = []\n",
    "# for package\n",
    "for index in range(len(packages)):\n",
    "    image_base_path = f\"{image_path}{packages[index]}/\"\n",
    "    masks_base_path = f\"{annotation_path}{packages[index]}/masks/\"\n",
    "\n",
    "    file_list = os.listdir(masks_base_path)\n",
    "    pattern = '*.png'\n",
    "    for filename in file_list:\n",
    "        if fnmatch.fnmatch(filename, pattern):\n",
    "            mask_paths.append(os.path.join(masks_base_path, filename))\n",
    "            image_name = filename[:len(filename)-3]+\"jpg\"\n",
    "            image_paths.append(os.path.join(image_base_path, image_name))\n",
    "\n",
    "# split into train and val set\n",
    "size_all = len(image_paths)\n",
    "val_samples = int(size_all*val_size)\n",
    "random.Random(size_all).shuffle(image_paths)\n",
    "random.Random(size_all).shuffle(mask_paths)\n",
    "\n",
    "train_input_img_paths = image_paths[:-val_samples]\n",
    "train_target_mask_paths = mask_paths[:-val_samples]\n",
    "val_input_img_paths = image_paths[-val_samples:]\n",
    "val_target_mask_paths = mask_paths[-val_samples:]\n",
    "\n",
    "print(f\"Len train img: {len(train_input_img_paths)} len train mask: {len(train_target_mask_paths)}\")\n",
    "print(f\"Len val img: {len(val_input_img_paths)} len val mask: {len(val_target_mask_paths)}\")\n",
    "\n",
    "# Generators\n",
    "train_gen = DataGenerator(train_input_img_paths, train_target_mask_paths, **params)\n",
    "val_gen = DataGenerator(val_input_img_paths, val_target_mask_paths, **params)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 16\n",
    "f, axs = plt.subplots(c, 8, figsize=(50,c*3))\n",
    "i = 0\n",
    "\n",
    "batch_input_test = train_input_img_paths[:c]\n",
    "batch_target_test = train_target_mask_paths[:c]\n",
    "images, data = train_gen.data_generation(batch_input_test, batch_target_test)\n",
    "\n",
    "print(len(images))\n",
    "for y in range(c):\n",
    "    axs[y,0].imshow(images[i])\n",
    "    axs[y,0].title.set_text('input')\n",
    "    axs[y,1].imshow(data[i][:,:,0], cmap='plasma')\n",
    "    axs[y,1].title.set_text('outer')\n",
    "    axs[y,2].imshow(data[i][:,:,1], cmap='plasma')\n",
    "    axs[y,2].title.set_text('middle_curb')\n",
    "    axs[y,3].imshow(data[i][:,:,2], cmap='plasma')\n",
    "    axs[y,3].title.set_text('guide_lane')\n",
    "    axs[y,4].imshow(data[i][:,:,3], cmap='plasma')\n",
    "    axs[y,4].title.set_text('solid_lane')\n",
    "    axs[y,5].imshow(data[i][:,:,4], cmap='plasma')\n",
    "    axs[y,5].title.set_text('hold_line')\n",
    "    axs[y,6].imshow(data[i][:,:,5], cmap='plasma')\n",
    "    axs[y,6].title.set_text('zebra')\n",
    "    axs[y,7].imshow(data[i][:,:,6], cmap='plasma')\n",
    "    axs[y,7].title.set_text('background')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models_backbone as models_b\n",
    "\n",
    "model = models_b.reference('LANESEGMENTATION_REFERENCE', input_height, input_width, number_classes)\n",
    "#model = custom_unet()\n",
    "#model = segmentation_model()\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "    \n",
    "filepath=\"./model/ld_autosys_checkpoint.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "history = model.fit(train_gen,\n",
    "            validation_data=val_gen,\n",
    "            epochs=epochs,\n",
    "            use_multiprocessing=False,\n",
    "            workers=6,\n",
    "            callbacks=callbacks_list)\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation iou_score values\n",
    "plt.figure(figsize=(30, 5))\n",
    "plt.subplot(121)\n",
    "plt.plot(history.history['iou_score'])\n",
    "plt.plot(history.history['val_iou_score'])\n",
    "plt.title('Model iou_score')\n",
    "plt.ylabel('iou_score')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.subplot(122)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.savefig('custom.png')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model only if not trained in this session\\\n",
    "model = load_model('./model/ld_autosys.h5', custom_objects={'iou_score':None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load some test images\n",
    "cnt = 10\n",
    "\n",
    "batch_input_test = train_input_img_paths[:cnt]\n",
    "batch_target_test = train_target_ann_paths[:cnt]\n",
    "images, data = train_gen.data_generation(batch_input_test, batch_target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(np.array(images))[:cnt]\n",
    "\n",
    "thres_value = 0.2\n",
    "\n",
    "def postprocess_channel(img):\n",
    "    #img = cv2.medianBlur(img, 3)\n",
    "    _, img = cv2.threshold(img,thres_value,1.0,cv2.THRESH_BINARY)\n",
    "    return img\n",
    "\n",
    "f, axs = plt.subplots(len(predictions), 8, figsize=(50,len(predictions)*3))\n",
    "for i, prediciton in enumerate(predictions):\n",
    "    #test_img = cv2.resize(test_imgs[i], (x_values, y_values))\n",
    "    test_img = images[i]\n",
    "    test_img = test_img.astype(np.float32)\n",
    "    predicted_lanes = np.sum([postprocess_channel(prediciton[:,:,i]) for i in range(6)], axis=0)\n",
    "    predicted_lanes = cv2.merge([np.zeros_like(predicted_lanes), np.zeros_like(predicted_lanes), predicted_lanes])\n",
    "    predicted_lanes = cv2.resize(predicted_lanes, (test_img.shape[1], test_img.shape[0]))\n",
    "    overlay_image = cv2.addWeighted(test_img, 0.5, predicted_lanes, 0.5, 0)\n",
    "    axs[i,0].imshow(overlay_image)\n",
    "    #axs[i,0].imshow(test_imgs[i])\n",
    "\n",
    "    axs[i,1].imshow(postprocess_channel(prediciton[:,:,0]), cmap='plasma')\n",
    "    axs[i,1].title.set_text('outer')\n",
    "    axs[i,2].imshow(postprocess_channel(prediciton[:,:,1]), cmap='plasma')\n",
    "    axs[i,2].title.set_text('middle_curb')\n",
    "    axs[i,3].imshow(postprocess_channel(prediciton[:,:,2]), cmap='plasma')\n",
    "    axs[i,3].title.set_text('guide_lane')\n",
    "    axs[i,4].imshow(postprocess_channel(prediciton[:,:,3]), cmap='plasma')\n",
    "    axs[i,4].title.set_text('solid_lane')\n",
    "    axs[i,5].imshow(postprocess_channel(prediciton[:,:,4]), cmap='plasma')\n",
    "    axs[i,5].title.set_text('hold_line')\n",
    "    axs[i,6].imshow(postprocess_channel(prediciton[:,:,5]), cmap='plasma')\n",
    "    axs[i,6].title.set_text('zebra')\n",
    "    axs[i,7].imshow(postprocess_channel(prediciton[:,:,6]), cmap='plasma')\n",
    "    axs[i,7].title.set_text('background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
