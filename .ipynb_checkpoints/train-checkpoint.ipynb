{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install segmentation-models albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# include include folder\n",
    "import sys\n",
    "sys.path.append(\"./miniaturautonomie_lanedetection/include/\")\n",
    "sys.path.append(\"./include/\")\n",
    "\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import fnmatch\n",
    "import random\n",
    "import cv2\n",
    "import json\n",
    "\n",
    "import supervisely_parser as svp\n",
    "import render\n",
    "import evaluation as evl\n",
    "from DataGenerator import DataGenerator\n",
    "\n",
    "import segmentation_models as sm # for simple segmentation architecture\n",
    "\n",
    "import albumentations as Alb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'reference' # should be changed for every new test run\n",
    "\n",
    "annotation_path = './annotation_v3.0/'\n",
    "image_path = './data/'\n",
    "packages = ['knuff_main1', 'knuff_main2', 'knuff_main3', 'knuff_hill', 'uni', 'highway', 'knuff_main5', 'knuff_main6']\n",
    "\n",
    "output_dir = f\"./output/{name}\"\n",
    "model_path = f\"{output_dir}/model.h5\"\n",
    "\n",
    "input_img_size = (480, 640)\n",
    "\n",
    "number_classes = 7 # outer, middle_curb, guide_lane, solid_lane, hold_line, zebra, background\n",
    "output_width = 640 \n",
    "output_height = 224 \n",
    "input_width = 640 \n",
    "input_height = 224\n",
    "\n",
    "val_size = 0.2 # percentage\n",
    "augmentation = True\n",
    "\n",
    "batch_size = 16\n",
    "epochs = 5\n",
    "\n",
    "transform = Alb.Compose([\n",
    "    Alb.ShiftScaleRotate(p=0.2),\n",
    "    Alb.RandomContrast(p=0.4),\n",
    "    Alb.RandomBrightness(limit=[-0.2,0.2], p=0.4)\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'batch_size': batch_size,\n",
    "    'input_img_size': input_img_size,\n",
    "    'target_img_size': (output_height, output_width),\n",
    "    'shuffle': True,\n",
    "    'n_channels': number_classes,\n",
    "    'transform': transform,\n",
    "    'augmentation': augmentation\n",
    "}\n",
    "\n",
    "#################################################################\n",
    "# run only if to rerender all masks or new packages are added\n",
    "#render.render_packages(packages, annotation_path, input_img_size)\n",
    "#################################################################\n",
    "\n",
    "# create output dir for every generated file\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# generate absolute list of all img and masks paths\n",
    "image_paths = []\n",
    "mask_paths = []\n",
    "# for package\n",
    "for index in range(len(packages)):\n",
    "    image_base_path = f\"{image_path}{packages[index]}/\"\n",
    "    masks_base_path = f\"{annotation_path}{packages[index]}/masks/\"\n",
    "\n",
    "    file_list = os.listdir(masks_base_path)\n",
    "    pattern = '*.png'\n",
    "    for filename in file_list:\n",
    "        if fnmatch.fnmatch(filename, pattern):\n",
    "            mask_paths.append(os.path.join(masks_base_path, filename))\n",
    "            image_name = filename[:len(filename)-3]+\"jpg\"\n",
    "            image_paths.append(os.path.join(image_base_path, image_name))\n",
    "\n",
    "# split into train and val set\n",
    "size_all = len(image_paths)\n",
    "val_samples = int(size_all*val_size)\n",
    "random.Random(size_all).shuffle(image_paths)\n",
    "random.Random(size_all).shuffle(mask_paths)\n",
    "\n",
    "train_input_img_paths = image_paths[:-val_samples]\n",
    "train_target_mask_paths = mask_paths[:-val_samples]\n",
    "val_input_img_paths = image_paths[-val_samples:]\n",
    "val_target_mask_paths = mask_paths[-val_samples:]\n",
    "\n",
    "print(f\"Len train img: {len(train_input_img_paths)} len train mask: {len(train_target_mask_paths)}\")\n",
    "print(f\"Len val img: {len(val_input_img_paths)} len val mask: {len(val_target_mask_paths)}\")\n",
    "\n",
    "# Generators\n",
    "train_gen = DataGenerator(train_input_img_paths, train_target_mask_paths, **params)\n",
    "val_gen = DataGenerator(val_input_img_paths, val_target_mask_paths, **params)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 16\n",
    "f, axs = plt.subplots(c, 8, figsize=(50,c*3))\n",
    "i = 0\n",
    "\n",
    "batch_input_test = train_input_img_paths[:c]\n",
    "batch_target_test = train_target_mask_paths[:c]\n",
    "images, data = train_gen.data_generation(batch_input_test, batch_target_test)\n",
    "\n",
    "print(len(images))\n",
    "for y in range(c):\n",
    "    axs[y,0].imshow(images[i])\n",
    "    axs[y,0].title.set_text('input')\n",
    "    axs[y,1].imshow(data[i][:,:,0], cmap='plasma')\n",
    "    axs[y,1].title.set_text('outer')\n",
    "    axs[y,2].imshow(data[i][:,:,1], cmap='plasma')\n",
    "    axs[y,2].title.set_text('middle_curb')\n",
    "    axs[y,3].imshow(data[i][:,:,2], cmap='plasma')\n",
    "    axs[y,3].title.set_text('guide_lane')\n",
    "    axs[y,4].imshow(data[i][:,:,3], cmap='plasma')\n",
    "    axs[y,4].title.set_text('solid_lane')\n",
    "    axs[y,5].imshow(data[i][:,:,4], cmap='plasma')\n",
    "    axs[y,5].title.set_text('hold_line')\n",
    "    axs[y,6].imshow(data[i][:,:,5], cmap='plasma')\n",
    "    axs[y,6].title.set_text('zebra')\n",
    "    axs[y,7].imshow(data[i][:,:,6], cmap='plasma')\n",
    "    axs[y,7].title.set_text('background')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models_backbone as models_b\n",
    "metrics = [sm.metrics.iou_score, evl.precision,evl.recall,evl.f1_score]\n",
    "\n",
    "model = models_b.reference('LANESEGMENTATION_REFERENCE', input_height, input_width, number_classes, metrics)\n",
    "#model = custom_unet()\n",
    "#model = segmentation_model()\n",
    "\n",
    "plot_model(model, f\"{output_dir}/model.png\", show_shapes=True, show_dtype=False, show_layer_names=True)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "    \n",
    "filepath=f\"{output_dir}/checkpoint.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "history = model.fit(train_gen,\n",
    "            validation_data=val_gen,\n",
    "            epochs=epochs,\n",
    "            use_multiprocessing=False,\n",
    "            workers=6,\n",
    "            callbacks=callbacks_list)\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "# Plot training & validation loss values\n",
    "plt.subplot(231)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "\n",
    "# Plot training & validation iou_score values\n",
    "plt.subplot(232)\n",
    "plt.plot(history.history['iou_score'])\n",
    "plt.plot(history.history['val_iou_score'])\n",
    "plt.title('Model iou_score')\n",
    "plt.ylabel('iou_score')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "\n",
    "plt.subplot(233)\n",
    "plt.plot(history.history['recall'])\n",
    "plt.plot(history.history['val_recall'])\n",
    "plt.title('Model recall mean')\n",
    "plt.ylabel('recall')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "\n",
    "plt.subplot(234)\n",
    "plt.plot(history.history['precision'])\n",
    "plt.plot(history.history['val_precision'])\n",
    "plt.title('Model precision mean')\n",
    "plt.ylabel('precision')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "\n",
    "plt.subplot(235)\n",
    "plt.plot(history.history['f1_score'])\n",
    "plt.plot(history.history['val_f1_score'])\n",
    "plt.title('Model F1 score mean')\n",
    "plt.ylabel('f1')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "\n",
    "\n",
    "plt.savefig(f\"{output_dir}/{name}_plot.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model only if not trained in this session\n",
    "model = load_model(f\"{output_dir}/model.h5\", custom_objects={'iou_score':sm.metrics.iou_score, \n",
    "                                                            'f1-score':sm.metrics.f1_score, \n",
    "                                                            'precision':sm.metrics.precision, \n",
    "                                                            'recall':sm.metrics.recall})\n",
    "# load test images\n",
    "packages = ['knuff_main1']\n",
    "\n",
    "# generate absolute list of all img and masks paths\n",
    "image_paths = []\n",
    "mask_paths = []\n",
    "# for package\n",
    "for index in range(len(packages)):\n",
    "    image_base_path = f\"{image_path}{packages[index]}/\"\n",
    "    masks_base_path = f\"{annotation_path}{packages[index]}/masks/\"\n",
    "\n",
    "    file_list = os.listdir(masks_base_path)\n",
    "    pattern = '*.png'\n",
    "    for filename in file_list:\n",
    "        if fnmatch.fnmatch(filename, pattern):\n",
    "            mask_paths.append(os.path.join(masks_base_path, filename))\n",
    "            image_name = filename[:len(filename)-3]+\"jpg\"\n",
    "            image_paths.append(os.path.join(image_base_path, image_name))\n",
    "\n",
    "test_batch_size = 16\n",
    "params = {\n",
    "    'batch_size': test_batch_size,\n",
    "    'input_img_size': input_img_size,\n",
    "    'target_img_size': (output_height, output_width),\n",
    "    'shuffle': False,\n",
    "    'n_channels': number_classes,\n",
    "    'augmentation': False\n",
    "}\n",
    "\n",
    "test_gen = DataGenerator(image_paths, mask_paths, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, iou, f1_score, precision, recall = model.evaluate(test_gen, verbose=0)\n",
    "print(\"Evaluation result:\")\n",
    "print(f\"Loss: {loss} \\nIoU: {iou} \\nF1: {f1_score} \\nPrecision: {precision} \\nRecall: {recall} \\n\")\n",
    "\n",
    "testbatch_imgs = image_paths[:test_batch_size]\n",
    "testbatch_masks = mask_paths[:test_batch_size]\n",
    "\n",
    "imgs, masks = test_gen.data_generation(testbatch_imgs, testbatch_masks)\n",
    "\n",
    "predictions = model.predict(imgs)\n",
    "\n",
    "thres_value = 0.1\n",
    "\n",
    "f, axs = plt.subplots(len(predictions), 3, figsize=(20,len(predictions)*3))\n",
    "for i, prediction in enumerate(predictions):\n",
    "    # show input img\n",
    "    axs[i,0].imshow(imgs[i])\n",
    "    axs[i,0].title.set_text('Original')\n",
    "    \n",
    "    # show prediction\n",
    "    ## clip to 0 or 1 with thres\n",
    "    clipped_pred = np.where(prediction > thres_value, 1, 0)\n",
    "    rgb_pred = render.render_rgb(clipped_pred)\n",
    "    \n",
    "    axs[i,1].imshow(rgb_pred)\n",
    "    axs[i,1].title.set_text('Prediction')\n",
    "    # show ground truth\n",
    "    rgb_gt = render.render_rgb(masks[i].astype(int))\n",
    "    \n",
    "    axs[i,2].imshow(rgb_gt)\n",
    "    axs[i,2].title.set_text('Ground Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
